[{"path":"https://pmparser.hugheylab.org/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jake Hughey. Author, maintainer. Josh Schoenbachler. Author. Elliot Outland. Author.","code":""},{"path":"https://pmparser.hugheylab.org/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hughey J, Schoenbachler J, Outland E (2025). pmparser: Create Maintain Relational Database Data PubMed/MEDLINE. R package version 1.0.21, https://github.com/hugheylab/pmparser, https://pmparser.hugheylab.org.","code":"@Manual{,   title = {pmparser: Create and Maintain a Relational Database of Data from PubMed/MEDLINE},   author = {Jake Hughey and Josh Schoenbachler and Elliot Outland},   year = {2025},   note = {R package version 1.0.21, https://github.com/hugheylab/pmparser},   url = {https://pmparser.hugheylab.org}, }"},{"path":"https://pmparser.hugheylab.org/index.html","id":"pmparser","dir":"","previous_headings":"","what":"Create and Maintain a Relational Database of Data from PubMed/MEDLINE","title":"Create and Maintain a Relational Database of Data from PubMed/MEDLINE","text":"pmparser enables one easily create maintain relational database data PubMed/MEDLINE. pmparser can download publicly available XML files, parse , incorporate PubMed’s regular updates, combine data NIH Open Citation Collection. PMDB, implementation database, available Zenodo (PostgreSQL dump) Google BigQuery. detailed description pmparser PMDB, check article.","code":""},{"path":[]},{"path":"https://pmparser.hugheylab.org/index.html","id":"option-1-cran","dir":"","previous_headings":"Installation","what":"Option 1: CRAN","title":"Create and Maintain a Relational Database of Data from PubMed/MEDLINE","text":"","code":"install.packages('pmparser')"},{"path":"https://pmparser.hugheylab.org/index.html","id":"option-2-hughey-lab-drat-repository","dir":"","previous_headings":"Installation","what":"Option 2: Hughey Lab Drat Repository","title":"Create and Maintain a Relational Database of Data from PubMed/MEDLINE","text":"Install BiocManager. use RStudio, go Tools → Global Options… → Packages → Add… (Secondary repositories), enter: Name: hugheylab Url: https://hugheylab.github.io/drat/ . can install update package entering: Alternatively, can install update package entering:","code":"if (!requireNamespace('BiocManager', quietly = TRUE))   install.packages('BiocManager') BiocManager::install('pmparser') BiocManager::install('pmparser', site_repository = 'https://hugheylab.github.io/drat/')"},{"path":"https://pmparser.hugheylab.org/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Create and Maintain a Relational Database of Data from PubMed/MEDLINE","text":"See examples detailed guidance reference documentation.","code":""},{"path":"https://pmparser.hugheylab.org/reference/getCitation.html","id":null,"dir":"Reference","previous_headings":"","what":"Get public-domain citation data — getCitation","title":"Get public-domain citation data — getCitation","text":"Get latest version NIH Open Citation Collection figshare , optionally write database. function requires shell command unzip, available default Unix systems. function normally called directly, called modifyPubmedDb().","code":""},{"path":"https://pmparser.hugheylab.org/reference/getCitation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get public-domain citation data — getCitation","text":"","code":"getCitation(   localDir,   filename = \"open_citation_collection.zip\",   nrows = Inf,   tableSuffix = NULL,   overwrite = FALSE,   con = NULL,   checkMd5 = TRUE )"},{"path":"https://pmparser.hugheylab.org/reference/getCitation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get public-domain citation data — getCitation","text":"localDir String indicating path directory containing citation file citation file downloaded. filename String indicating name citation file. normally changed default. nrows Number indicating many rows citation file read. normally changed default. tableSuffix String indicating suffix, , append table name. overwrite Logical indicating whether overwrite existing table. con Connection database, created using DBI::dbConnect(). checkMd5 Logical indicating whether download citation file MD5 sums local remote versions match. normally changed default.","code":""},{"path":"https://pmparser.hugheylab.org/reference/getCitation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get public-domain citation data — getCitation","text":"con NULL, function returns data.table columns citing_pmid cited_pmid. Beware large table swamp machine's memory. con NULL, function returns NULL invisibly.","code":""},{"path":[]},{"path":"https://pmparser.hugheylab.org/reference/getCitation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get public-domain citation data — getCitation","text":"","code":"if (FALSE) { # \\dontrun{ dCitation = getCitation('.') } # }"},{"path":"https://pmparser.hugheylab.org/reference/getPgParams.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Postgres connection parameters — getPgParams","title":"Get Postgres connection parameters — getPgParams","text":"helper function get parameters .pgpass file. See details.","code":""},{"path":"https://pmparser.hugheylab.org/reference/getPgParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Postgres connection parameters — getPgParams","text":"","code":"getPgParams(path = \"~/.pgpass\")"},{"path":"https://pmparser.hugheylab.org/reference/getPgParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Postgres connection parameters — getPgParams","text":"path Path .pgpass file.","code":""},{"path":"https://pmparser.hugheylab.org/reference/getPgParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Postgres connection parameters — getPgParams","text":"data.table one row set parameters.","code":""},{"path":[]},{"path":"https://pmparser.hugheylab.org/reference/getPgParams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Postgres connection parameters — getPgParams","text":"","code":"pg = getPgParams(system.file('extdata', 'pgpass', package = 'pmparser'))"},{"path":"https://pmparser.hugheylab.org/reference/modifyPubmedDb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or update a PubMed database — modifyPubmedDb","title":"Create or update a PubMed database — modifyPubmedDb","text":"function downloads PubMed/MEDLINE XML files, parses , adds information database, downloads NIH Open Citation Collection adds database. recent version PMID retained. Parsing XML files use parallel backend one registered, doParallel::registerDoParallel().","code":""},{"path":"https://pmparser.hugheylab.org/reference/modifyPubmedDb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or update a PubMed database — modifyPubmedDb","text":"","code":"modifyPubmedDb(   localDir,   dbname,   dbtype = c(\"postgres\", \"mariadb\", \"mysql\", \"sqlite\"),   nFiles = Inf,   retry = TRUE,   nCitations = Inf,   mode = c(\"create\", \"update\"),   ... )"},{"path":"https://pmparser.hugheylab.org/reference/modifyPubmedDb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or update a PubMed database — modifyPubmedDb","text":"localDir Directory download files PubMed. dbname Name database. dbtype Type database, either 'postgres', 'mariadb', 'mysql', 'sqlite'. Make sure install corresponding DBI driver package first: RPostgres, RMariaDB ('mariadb' 'mysql'), RSQLite. Due large size database, SQLite recommended small-scale testing. nFiles Maximum number xml files parse already database. normally changed default. retry Logical indicating whether retry parsing steps fail. nCitations Maximum number rows citation file read. normally changed default. mode String indicating whether create database using baseline files update database using update files. ... arguments passed DBI::dbConnect().","code":""},{"path":"https://pmparser.hugheylab.org/reference/modifyPubmedDb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or update a PubMed database — modifyPubmedDb","text":"NULL, invisibly. Tab-delimited log files created logs folder localDir.","code":""},{"path":[]},{"path":"https://pmparser.hugheylab.org/reference/modifyPubmedDb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or update a PubMed database — modifyPubmedDb","text":"","code":"if (FALSE) { # \\dontrun{ modifyPubmedDb('.', 'pmdb', mode = 'create') } # }"},{"path":"https://pmparser.hugheylab.org/reference/parseElement.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse elements from a PubMed XML file — parseElement","title":"Parse elements from a PubMed XML file — parseElement","text":"Elements parsed according MEDLINE®PubMed® XML Element Descriptions Attributes . functions normally called directly, called modifyPubmedDb().","code":""},{"path":"https://pmparser.hugheylab.org/reference/parseElement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse elements from a PubMed XML file — parseElement","text":"","code":"parsePmidStatus(rawXml, filename, con = NULL, tableSuffix = NULL)  parseArticleId(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseArticle(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parsePubHistory(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseJournal(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parsePubType(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseMesh(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseKeyword(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseGrant(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseChemical(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseDataBank(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseComment(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseAbstract(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseOther(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseAuthor(pmXml, dPmid, con = NULL, tableSuffix = NULL)  parseInvestigator(pmXml, dPmid, con = NULL, tableSuffix = NULL)"},{"path":"https://pmparser.hugheylab.org/reference/parseElement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse elements from a PubMed XML file — parseElement","text":"rawXml xml document obtained loading PubMed XML file using xml2::read_xml(). filename string added column xml_filename. con Connection database, created using DBI::dbConnect(). tableSuffix String append table names. pmXml xml nodeset derived rawXml, returned parsePmidStatus(), node corresponds PMID. dPmid data.table one row node pmXml, columns pmid, version, possibly xml_filename.","code":""},{"path":"https://pmparser.hugheylab.org/reference/parseElement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse elements from a PubMed XML file — parseElement","text":"parsePmidStatus() returns list two objects. first xml nodeset node corresponds PubmedArticle rawXml object. second data.table columns pmid, version, xml_filename, status, row corresponds PubmedArticle rawXml object deleted pmid. status column parsed DeleteCitation MedlineCitation sections. following functions return data.table list data.tables columns dPmid plus columns specified. parseArticleId(): data.table columns id_type id_value, parsed ArticleIdList section. id_types \"doi\" \"pmc\" retained. parseArticle(): data.table columns title, language, vernacular_title, pub_model, pub_date, parsed Article section. parsePubHistory(): data.table columns pub_status pub_date, parsed History section. parseJournal(): data.table columns journal_name, journal_iso, pub_date, pub_year, pub_month, pub_day, medline_date, volume, issue, cited_medium, parsed Journal section. parsePubType(): data.table columns type_name type_id, parsed PublicationTypeList section. parseMesh(): list three data.tables parsed mostly MeshHeadingList section. first column indexing_method (parsed MedlineCitation section), second columns descriptor_pos, descriptor_name, descriptor_ui, descriptor_major_topic, third columns descriptor_pos, qualifier_name, qualifier_ui, qualifier_major_topic. parseKeyword(): list two data.tables parsed KeywordList section. first column list_owner, second columns keyword_name major_topic. parseGrant(): list two data.tables parsed GrantList section. first column complete, second columns grant_id, acronym, agency, country. parseChemical(): data.table columns registry_number, substance_name, substance_ui, parsed ChemicalList section. parseDataBank(): data.table columns data_bank_name accession_number, parsed DataBankList section. parseComment(): data.table columns ref_type ref_pmid, parsed CommentsCorrectionsList section. parseAbstract(): list two data.tables parsed Abstract section. first column copyright. second columns text, label, nlm_category. parseAuthor(): list data.tables parsed AuthorList section. first authors columns author_pos, last_name, fore_name, initials, suffix, valid, equal_contrib, collective_name. second affiliations columns author_pos, affiliation_pos, affiliation. third author identifiers columns author_pos, source, identifier. fourth author affiliation identifiers columns author_pos, affiliation_pos, source, identifier. fifth author list column complete. parseInvestigator(): list data.tables similar returned parseAuthor(), except parsed InvestigatorList section, column names containing \"investigator\" instead \"author\", first data.table lacks columns equal_contrib collective_name fifth data.table exist. parseOther(): list data.tables parsed OtherAbstract OtherID sections. first columns text, type, language. second columns source id_value.","code":""},{"path":[]},{"path":"https://pmparser.hugheylab.org/reference/parseElement.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parse elements from a PubMed XML file — parseElement","text":"","code":"library('data.table') library('xml2')  filename = 'pubmed20n1016.xml.gz' rawXml = read_xml(system.file('extdata', filename, package = 'pmparser'))  pmidStatusList = parsePmidStatus(rawXml, filename) pmXml = pmidStatusList[[1L]] dPmidRaw = pmidStatusList[[2L]] dPmid = dPmidRaw[status != 'Deleted', !'status']  dArticleId = parseArticleId(pmXml, dPmid) dArticle = parseArticle(pmXml, dPmid) dJournal = parseJournal(pmXml, dPmid) dPubType = parsePubType(pmXml, dPmid) dPubHistory = parsePubHistory(pmXml, dPmid) meshRes = parseMesh(pmXml, dPmid) keywordRes = parseKeyword(pmXml, dPmid) grantRes = parseGrant(pmXml, dPmid) dChemical = parseChemical(pmXml, dPmid) dDataBank = parseDataBank(pmXml, dPmid) dComment = parseComment(pmXml, dPmid) abstractRes = parseAbstract(pmXml, dPmid) authorRes = parseAuthor(pmXml, dPmid) investigatorRes = parseInvestigator(pmXml, dPmid) otherRes = parseOther(pmXml, dPmid)"},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1021","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.21","title":"pmparser 1.0.21","text":"Updated test standards based Jan 2025 update PubMed XML files.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1020","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.20","title":"pmparser 1.0.20","text":"CRAN release: 2024-01-13 Updated readme table test standards.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1019","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.19","title":"pmparser 1.0.19","text":"CRAN release: 2023-12-18 Updated test standards based annual update PubMed XML files.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1018","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.18","title":"pmparser 1.0.18","text":"CRAN release: 2023-12-01 Fixed parsing CitedMedium within Journal.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1017","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.17","title":"pmparser 1.0.17","text":"CRAN release: 2023-05-23 Updated parsing empty investigator fields.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1016","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.16","title":"pmparser 1.0.16","text":"CRAN release: 2023-02-12 Updated readme table test standards.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1015","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.15","title":"pmparser 1.0.15","text":"CRAN release: 2022-12-13 Changed ftp URLs https. Updated test standards based new PubMed XML files.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1014","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.14","title":"pmparser 1.0.14","text":"Added columns language vernacular_title article table.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1013","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.13","title":"pmparser 1.0.13","text":"CRAN release: 2022-11-24 Added tables OtherAbstract OtherID sections.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1012","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.12","title":"pmparser 1.0.12","text":"Fixed issues found lintr.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1011","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.11","title":"pmparser 1.0.11","text":"CRAN release: 2022-11-08 Updated test standards based PubMed’s updated README.txt.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-1010","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.10","title":"pmparser 1.0.10","text":"CRAN release: 2022-04-27 Added import curl::curl() circumvent check NOTE.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-109","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.9","title":"pmparser 1.0.9","text":"Clarified error message downloading PubMed files. Skip testing file downloads CRAN.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-108","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.8","title":"pmparser 1.0.8","text":"Increased timeout downloading citation file. Reordered steps check citation table even tables --date. Update match lab style standard.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-107","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.7","title":"pmparser 1.0.7","text":"Explicitly added curl Imports, since ’s used utils::download.file(). Set “HUGE” option xml2::read_xml() avoid occasional error.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-106","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.6","title":"pmparser 1.0.6","text":"Updated styling based linter.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-105","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.5","title":"pmparser 1.0.5","text":"Added abstract_pos column abstract table. pub_year journal table empty, now extracts pub_year medline_date.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-104","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.4","title":"pmparser 1.0.4","text":"CRAN release: 2022-02-17 Updated test standards latest PubMed XML files. Returned doParallel scripts simplicity.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-103","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.3","title":"pmparser 1.0.3","text":"Simplified xml2 dependency, since new version now CRAN.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-102","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.2","title":"pmparser 1.0.2","text":"Fixed windows compatibility.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-101","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.1","title":"pmparser 1.0.1","text":"Revised code need globalVariables() order pass R CMD check without notes.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-100","dir":"Changelog","previous_headings":"","what":"pmparser 1.0.0","title":"pmparser 1.0.0","text":"Updated tests.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009036","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9036","title":"pmparser 0.0.0.9036","text":"Added data dictionary vignette table database.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009035","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9035","title":"pmparser 0.0.0.9035","text":"Remove rare, obnoxious unicode character keyword name.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009034","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9034","title":"pmparser 0.0.0.9034","text":"Explicitly set doFuture chunking dopar loops.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009033","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9033","title":"pmparser 0.0.0.9033","text":"Suppress irrelevant warnings future.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009032","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9032","title":"pmparser 0.0.0.9032","text":"%dopar% loops places now work doFuture.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009031","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9031","title":"pmparser 0.0.0.9031","text":"%dopar% loops getPubmedFiles() now work doFuture. Use updated version withr CRAN.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009030","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9030","title":"pmparser 0.0.0.9030","text":"Renamed internal functions consistency clarity.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009029","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9029","title":"pmparser 0.0.0.9029","text":"getCitation() now uses data.table::fread() write table chunks, ~3.3x faster. Switched dbAppendTable() dbWriteTable(..., append = TRUE) inexplicable speed increase.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009028","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9028","title":"pmparser 0.0.0.9028","text":"getCitation() now uses vroom arkdb::unark(). Moved DBI driver packages Suggests reduce dependencies.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009027","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9027","title":"pmparser 0.0.0.9027","text":"Removed obsolete copyright column abstract table.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009026","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9026","title":"pmparser 0.0.0.9026","text":"parseMesh() now returns additional table containing IndexingMethod attribute.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009025","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9025","title":"pmparser 0.0.0.9025","text":"Fixed rare case parsing function returning data.table NA columns instead data.table rows.","code":""},{"path":"https://pmparser.hugheylab.org/news/index.html","id":"pmparser-0009024","dir":"Changelog","previous_headings":"","what":"pmparser 0.0.0.9024","title":"pmparser 0.0.0.9024","text":"Switched using glue hood.","code":""}]
